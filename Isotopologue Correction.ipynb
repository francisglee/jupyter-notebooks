{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Due to natural abundance of various isotopes (ie - <sup>13</sup>C), as well as any modications that may occur duing chromatographic separation (we won't cover this in this notebook), we'll have to normalize our ```Fractional Abundance```.  Once we successfully perform this correction, we can move forward to evaluate the ```Fractional Enrichment``` of a particular metabolite, which, if regresses strongly to the test condition, can yield light to possible pathways that may be affected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two methods to normalize this data:\n",
    "\n",
    "1. Labeled data corrected via unlabeled dataset.\n",
    "2. Labeled data corrected via theoretical natural abundance estimates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have no unlabeled datasets, we'll have to go with option 2 in order to perform the Isotopologue Correction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assume 1.07% Natural Abundance for <sup>13</sup>C<sup>[7]</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$CM * I_{corr} = I_{meas}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "- $CM$ is the ```Correction Matrix```\n",
    "- $I_{corr}$ is the ```Corrected Matrix Distribution Vector```\n",
    "- $I_{meas}$ is the ```Measured Matrix Distribution Vector```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$I_{meas} = (I_{0}, I_{1}, I_{2}, ... I_{n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$l_{n} = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$FA_{I_{n}} =\\frac{l_{m_{k}}}{\\sum_{k=0}^n I_{m_{k}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in computing the Correction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define some core functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fractional_abundance()\n",
    "    '''\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial(n, k):\n",
    "    \"\"\"\n",
    "    A fast way to calculate binomial coefficients\n",
    "    \"\"\"\n",
    "    if 0 <= k <= n:\n",
    "        ntok = 1\n",
    "        ktok = 1\n",
    "        for t in range(1, min(k, n - k) + 1):\n",
    "            ntok *= n\n",
    "            ktok *= t\n",
    "            n -= 1\n",
    "        return ntok // ktok\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_of_isotopomers(num_carbon):\n",
    "    \n",
    "    num_iso = 0\n",
    "    \n",
    "    for x in range(num_carbon+1):\n",
    "        num_iso += binom(num_carbon, x)\n",
    "    \n",
    "    return num_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correction_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mvd_measured()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_isotopologue_correction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fractional_enrichment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pool_totals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fractional_contribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_isotopologue_correction(data, unlabeled):\n",
    "    \n",
    "    # average the unlabeled data by column\n",
    "    averages = np.average(unlabeled, axis=0).tolist() \n",
    "\n",
    "    diagonal_matrix = []\n",
    "    \n",
    "    num_rows = len(averages)\n",
    "    \n",
    "    # Make a copy of everything in averages in new list\n",
    "    # Add zeros at the front to make values sit on diagonal\n",
    "    # Slice the end to make it square\n",
    "    for row_number in range(num_rows):\n",
    "        averages_copy = list(averages)\n",
    "        averages_zeros  = [0] * row_number + averages_copy\n",
    "        averages_sliced = averages_zeros[:num_rows]\n",
    "        diagonal_matrix.append(averages_sliced)\n",
    "\n",
    "    diagonal_matrix = np.array(diagonal_matrix)\n",
    "    #print(diagonal_matrix)\n",
    "\n",
    "    inverse = np.linalg.inv(diagonal_matrix)\n",
    "    normalised = np.dot(data, inverse)\n",
    "\n",
    "    # Numpy vector where <n>th element is the sum of row <n>\n",
    "    data_rows = len(data)\n",
    "    #print(data_rows)\n",
    "    row_sums = np.sum(normalised, axis=1)\n",
    "    for row_number in range(data_rows):\n",
    "        normalised[row_number, :] *= 100/row_sums[row_number]\n",
    "    return normalised \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_analysis(all_data_input):\n",
    "    # Read in data file line by line\n",
    "    data = []\n",
    "    all_data_input = all_data_input.replace(',', '\\t')\n",
    "    for line in all_data_input.split('\\n'):\n",
    "        # If the line is a whitespace error from excel ignore it\n",
    "        if line.isspace():\n",
    "            continue\n",
    "        #strip line to deal with trailing commas\n",
    "        strip_line = line.rstrip('\\t')\n",
    "        \n",
    "        data_line = []\n",
    "        for str_float in strip_line.split('\\t'):\n",
    "            if not str_float.isspace():\n",
    "                data_line.append(float(str_float))\n",
    "        data.append(data_line)\n",
    "    data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_unlabeled_for_analysis(user_unlabeled_data):\n",
    "    unlabeled = np.array(\n",
    "        list(csv.reader(user_unlabeled_data.split('\\n'), delimiter=\",\")),\n",
    "    ).astype(np.float)\n",
    "    return unlabeled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files in and identify keys e.g.\n",
    "#    if there are files like:\n",
    "#      [set-a_unlabeled, set-b_unlabeled, set-a_data, set-b_data]\n",
    "#    produce\n",
    "#      [set-a, set-b]\n",
    "job_keys = set()\n",
    "filenames = os.listdir()\n",
    "for filename in filenames:\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    # Find just the basename\n",
    "    basename = basename.replace('_unlabeled', '').replace('_data', '')\n",
    "    job_keys.add(basename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all the possible job keys e.g. set-a, set-b, 3hb-coa, etc\n",
    "#    open the files, get the data and run job\n",
    "#    ignore job keys from random files that do not have the _unlabeled and _data\n",
    "valid_jobs = set()\n",
    "for job_key in job_keys:\n",
    "    # Check that there exists <job_key>_unlabeled AND <job_key>_data\n",
    "    unlabeled_fname = '{0}_unlabeled.csv'.format(job_key)\n",
    "    data_fname = '{0}_data.csv'.format(job_key)\n",
    "    # TODO maybe check for both .txt and .csv above for robustness\n",
    "    if unlabeled_fname in filenames and data_fname in filenames:\n",
    "        valid_jobs.add(job_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each job  in valid_jobs, load into numpy, do analyis, write result\n",
    "for job_key in valid_jobs:\n",
    "    unlabeled_fname = '{0}_unlabeled.csv'.format(job_key)\n",
    "    data_fname = '{0}_data.csv'.format(job_key)\n",
    "\n",
    "    # Call function from tracerutils to prepare unlabeled data from CSV (or web)\n",
    "    # Cleans up trailing commas, non numbers, etc\n",
    "    text_from_unlabeled_file = open(unlabeled_fname).read()\n",
    "    unlabeled = prepare_unlabeled_for_analysis(text_from_unlabeled_file)\n",
    "\n",
    "    # Call function from tracerutils to prepare data from CSV (or web)\n",
    "    # for analysis. Needs to strip trailing commas, fix non numbers etc.\n",
    "    text_from_data_file = open(data_fname).read()    \n",
    "    data = prepare_data_for_analysis(text_from_data_file)\n",
    "\n",
    "    #print('averages:', averages)\n",
    "    print('data:', data)\n",
    "\n",
    "    result = perform_isotopologue_correction(data, unlabeled)\n",
    "    \n",
    "    # print to a file\n",
    "    output_fname = '{0}_output.csv'.format(job_key)\n",
    "    np.savetxt(output_fname, result, fmt='%.1f', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
