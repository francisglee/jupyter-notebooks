{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "\n",
    "> The goal of this notebook is to play around with the `BAM`/`SAM`, `BCF`/`VCF`, and `FASTA`/`FASTQ` file.  It's been years since I've done any variant calling, and I'm curious to see how well I can work with them in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tutorials__:\n",
    "\n",
    "- [Working with Genomic Data in Python](http://fullstackdatascientist.io/15/03/2016/genomic-data-visualization-using-python/)\n",
    "- [Extracting Data Files from VCF](http://alimanfoo.github.io/2017/06/14/read-vcf.html)\n",
    "- [Framework for Evaluating Variant Detection Methods](https://bcb.io/2013/05/06/framework-for-evaluating-variant-detection-methods-comparison-of-aligners-and-callers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "__Database Access__:\n",
    "\n",
    "- ~~[cruzdb](https://github.com/brentp/cruzdb): UCSC genomes database~~ \n",
    "- [pyensembl](https://github.com/openvax/pyensembl): Ensembl\n",
    "- ~~[bioservices](https://github.com/cokelaer/bioservices): ArrayExpress, BioModels, ChEBI, KEGG, PDB, Uniprot, UniChem, NCBIBlast~~\n",
    "\n",
    "__File Handling__:\n",
    " \n",
    "- [bamnostic](https://github.com/betteridiot/bamnostic): `BAM`\n",
    "- [pysamstats](https://github.com/alimanfoo/pysamstats): `BAM` _commandline tool_\n",
    "- [pyVCF](https://github.com/jamescasbon/PyVCF): `VCF`\n",
    "- [pyfaidx](https://github.com/mdshw5/pyfaidx): `FASTA`\n",
    "- [fastq-and-furious](https://github.com/lgautier/fastq-and-furious): `FASTQ`\n",
    "- ~~[cyvcf2](https://github.com/brentp/cyvcf2): `VCF` and `BCF`~~ \n",
    "- [pysam](https://github.com/pysam-developers/pysam): `SAM`, `BAM`, `VCF`, and `BCF`\n",
    "- [pybedtools](https://github.com/daler/pybedtools): `BAM`, `SAM`, `BED`, `BCF`, `VCF`, `GFF`, and `GTF` \n",
    "- [htseq](https://github.com/simon-anders/htseq): `FASTQ`, `BAM`, `SAM`, `VCF`, `BED`\n",
    "- [biopython](https://github.com/biopython/biopython): DNA, RNA, Proteins, `FASTQ`\n",
    "- [scikit-allel](https://github.com/cggh/scikit-allel): `VCF`\n",
    "\n",
    "* trouble installing cyVCF2\n",
    "\n",
    "__Quality Control__:\n",
    "\n",
    "- ~~[AfterQC](https://github.com/OpenGene/AfterQC): `FASTQ` file Processing~~\n",
    "- [fastqp](https://github.com/mdshw5/fastqp): `FASTQ`, `BAM`, and `SAM` file Processing\n",
    "- ~~[bam-toolbox](https://github.com/AndersenLab/bam-toolbox) `BAM` coverage~~\n",
    "- ~~[mergesam](https://github.com/DarwinAwardWinner/mergesam): `SAM` and `BAM` conversion and merging and sorting~~\n",
    "\n",
    "__Variant Calling__:\n",
    "\n",
    "- [freebayes](https://github.com/ekg/freebayes): a haplotype-based variant detector\n",
    "- [gatk](https://software.broadinstitute.org/gatk/): assortment of variant callers\n",
    "- [bcftools](http://www.htslib.org/): assortment of variant callers\n",
    "\n",
    "__Visualization__:\n",
    "\n",
    "- ~~[Biodalliance](https://github.com/dasmoth/dalliance): visualize `BAM`, `VCF`~~\n",
    "- [GenomeView](https://github.com/nspies/genomeview): visualize `BAM`\n",
    "- [plotly](https://github.com/plotly): general-purpose graphing library\n",
    "- [seaborn](https://github.com/mwaskom/seaborn): general-purpose graphing library\n",
    "- [altair](https://github.com/altair-viz/altair): statistical visualization\n",
    "\n",
    "__Report Generation__:\n",
    "\n",
    "- [MultiQC](https://github.com/ewels/MultiQC): Aggregate results from bioinformatics analyses across many samples into a single report\n",
    "- [Jupyter Notebook](https://github.com/jupyter/notebook)\n",
    "- [pyPipeline](https://github.com/AndersenLab/pyPipeline)\n",
    "- [bcbio](https://github.com/bcbio/bcbio-nextgen)\n",
    "\n",
    "__Math/Stat__:\n",
    "\n",
    "- [pandas](https://github.com/pandas-dev/pandas)\n",
    "- [scipy](https://github.com/scipy/scipy)\n",
    "- [cython](https://github.com/cython/cython)\n",
    "\n",
    "__Tutorials__:\n",
    "\n",
    "- [samtools tutorial](http://quinlanlab.org/tutorials/samtools/samtools.html)\n",
    "- [ngs alignment and variant calling](https://github.com/ekg/alignment-and-variant-calling-tutorial)\n",
    "- [scikit-allel](http://alimanfoo.github.io/2017/06/14/read-vcf.html)\n",
    "- [genomic data visualization](http://fullstackdatascientist.io/15/03/2016/genomic-data-visualization-using-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's sanity check out packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import itertools\n",
    "from collections import OrderedDict \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pysam as ps\n",
    "import vcf\n",
    "import bamnostic as bs\n",
    "import pybedtools as bt\n",
    "import HTSeq as hs\n",
    "import fastqandfurious\n",
    "from Bio import SeqIO\n",
    "import allel\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define __PATHs__ for our data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aln1_path = \"/home/ifrancium/Documents/amplicon-ngs-workflow/notebooks/data/original_data/aln1.fastq\"\n",
    "aln2_path = \"/home/ifrancium/Documents/amplicon-ngs-workflow/notebooks/data/original_data/aln2.fastq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_path = \"/home/ifrancium/Documents/amplicon-ngs-workflow/notebooks/data/samtools_output/aln_sorted.bam\"\n",
    "bai_path = \"/home/ifrancium/Documents/amplicon-ngs-workflow/notebooks/data/samtools_output/aln_sorted.bam.bai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_path = \"/home/ifrancium/Documents/amplicon-ngs-workflow/notebooks/data/samtools_output/aln.sam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf3_path = \"/home/ifrancium/Documents/amplicon-ngs-workflow/reference_sequences/Homo_sapiens.GRCh37/Homo_sapiens.GRCh37.87.gtf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = \"/home/ifrancium/Documents/amplicon-ngs-workflow/notebooks/data/jupyter_outputs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look inside the FASTQ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aln1 = hs.FastqReader(aln1_path)\n",
    "aln2 = hs.FastqReader(aln2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \", sum(1 for x in aln1), \" reads in the aln1 FASTQ file.\")\n",
    "print(\"There are \", sum(1 for x in aln2), \" reads in the aln2 FASTQ file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`aln1` indicates the forward reads, and `aln2` indicates the reverse reads.  I'm a big fan of `pandas.DataFrame`, so let's try to mash everything in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 575002\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "print(\"Printing the first {} reads in aln1:\".format(sample_size))\n",
    "\n",
    "aln1_fastq_reads = []\n",
    "\n",
    "for cnt, fastq_read in enumerate(itertools.islice(aln1, sample_size)):\n",
    "    read_dict = {\"Name\": fastq_read.name, \"Sequence\": str(fastq_read), \"Phred Score\": fastq_read.qual, \"Length\": len(fastq_read)}\n",
    "    aln1_fastq_reads.append(read_dict)  \n",
    "\n",
    "    print(cnt, \"Read Length: \", len(fastq_read), \", Average Phred Score: \", np.sum(fastq_read.qual)/len(fastq_read))\n",
    "\n",
    "\n",
    "# construct dataframe\n",
    "aln1_fastq_df = pd.DataFrame(aln1_fastq_reads)\n",
    "\n",
    "t_stop = time.time()\n",
    "t_total = t_stop - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = 5\n",
    "\n",
    "print(\"There are \", len(aln1_fastq_df.index), \" reads in this dataframe.\")\n",
    "print(\"This job took {} seconds to complete.\".format(t_total))\n",
    "print(\"Printing the first {} rows of the dataframe:\".format(head))\n",
    "aln1_fastq_df.head(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's back up this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aln1_fastq_df.to_csv(dump_path + \"aln1_FASTQ.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move onto the `aln2` FASTQ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 575002\n",
    "\n",
    "t_start2 = time.time()\n",
    "\n",
    "print(\"Printing the first {} reads in aln2:\".format(sample_size))\n",
    "\n",
    "aln2_fastq_reads = []\n",
    "\n",
    "for cnt, fastq_read in enumerate(itertools.islice(aln2, sample_size)):\n",
    "    read_dict = {\"Name\": fastq_read.name, \"Sequence\": str(fastq_read), \"Phred Score\": fastq_read.qual, \"Length\": len(fastq_read)}\n",
    "    aln2_fastq_reads.append(read_dict)  \n",
    "\n",
    "    print(cnt, \"Read Length: \", len(fastq_read), \", Average Phred Score: \", np.sum(fastq_read.qual)/len(fastq_read))\n",
    "\n",
    "# construct dataframe\n",
    "aln2_fastq_df = pd.DataFrame(aln2_fastq_reads)\n",
    "\n",
    "t_stop2 = time.time()\n",
    "t_total2 = t_stop2 - t_start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head2 = 5\n",
    "\n",
    "print(\"There are \", len(aln2_fastq_df.index), \" reads in this dataframe.\")\n",
    "print(\"This job took {} seconds to complete.\".format(t_total2))\n",
    "print(\"Printing the first {} rows of the dataframe:\".format(head2))\n",
    "aln2_fastq_df.head(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's back up this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aln2_fastq_df.to_csv(dump_path + \"aln2_FASTQ.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look inside the BAM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aln = hs.BAM_Reader(bam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \", sum(1 for x in aln), \" alignment reads in this BAM file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(aln))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know all the methods of this object: `<class 'HTSeq.BAM_Reader'>`.  Let's start out with the alignment reads data.  These reads are `HTSeq.SAM_Alignment` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `HTSeq.SAM_Alignment` Object Attributes\n",
    "\n",
    "> Note: I put `(iterable)` in with some of the Return Types.  This is not accurate and a bit confusing.  This is meant to convey that the dunder functions returned a string (or whatever object type is specified) to the terminal, but the return type is actually a unique class object, which contains that particular type object returned by the dunder function.   \n",
    "\n",
    "| Name | Return Type | Description |\n",
    "|------|-------------|-------------|\n",
    "| `.read` | str (iterable) | A Sequence object (str) holds a DNA sequence.  May have a `descr` (str) attribute. |\n",
    "| `.aligned` | bool | `True` if aligned, `False` if not aligned.  This is determined by the aligner. |\n",
    "| `.iv` | list (iterable) | contains `chrom` (str), `start` (int), `end` (int), and `strand` (str) in the following format: `chrom:start-end/strand` |\n",
    "| `.paired_end` | bool | `True` if read stems from a paired-end sequencing run, and `False` if not. |\n",
    "| `.read_as_aligned` | str (iterable) | `read` attribute always presents the read in the order in which it was sequenced. This attribute undoes the reverse-complement (if performed at all), and the `read` attribute is as it was found in the file. | \n",
    "| `.read_as_sequenced` | str (iterable) | This attribute performs a reverse-complement on the sequencing read if the aligner reverse-complemented the sequencing read to align it to the (+) strand. |\n",
    "| `.aQual` | int | The alignment quality score in Phread style encoding. |\n",
    "|`.cigar` | list | A list of `CigarOperation` objects, as parsed from the extended CIGAR string. These objects have the following attributes: `type`, `size`, `ref_iv`, `query_from`, `query_to`, `check()`. |\n",
    "| `.not_primary_alignment` | bool | Returns `True` if `0x100` flag is present during alignment.  This is indicative of secondary alignment, which refers to multiple alignments. |\n",
    "| `.failed_platform_qc` | bool | Returns `True` if the read failed a platform quality check.  This is accompanied by a `0x200` flag. |\n",
    "| `.pcr_or_optical_duplicate` | bool | Returns `True` if the read is a PCR or optical duplicate.  This is accompanied by a `0x400` flag.\n",
    "| `.supplementary` | bool | Returns `True` if `0x800` flag is present during alignment.  This suggests chimeric/non-linear alignments. | \n",
    "| `.optional_field(tag)` | str | Returns the optional field `tag`, which are two-letter strings found at the beginning of the header lines. | \n",
    "| `.optional_fields` | dict | Returns a dict with all optional fields, using their `tags` as `keys`. | \n",
    "| `.get_sam_lines()` | str | Constructs a SAM line to describe the alignment |\n",
    "| `.mate_aligned` | bool | Only available if `.paired_end == True`.  Returns `true` if the pair (__mates__) was aligned. |\n",
    "| `.pe_which` | str | Only available if `.paired_end == True`.  Takes one of the values `first`, `second`, `unknown` and `not_paired_end`, to indicate whether the read stems from the first or second pass of the paired-end sequencing. |\n",
    "| `.proper_pair` | Bool | Only available if `.paired_end == True`.  Returns `True` if the mates formed a proper alignment with each other and to the reference.  This is indicated by the `0x0002` flag. |\n",
    "| `.mate_start` | int (iterable) | Only available if `.paired_end == True`.  The start (i.e., left-most position) of the mate’s alignment. Note that `mate_start.strand` is opposite to `iv.strand` for proper pairs. |\n",
    "| `.inferred_insert_size` | int | Only available if `.paired_end == True`.  Denotes the zize of the insert between the reads.  If the reads overlap, `.inferred_insert_size` would be negative. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SAM`/`BAM` Alignment Attributes\n",
    "\n",
    "> As per the [working](https://samtools.github.io/hts-specs/SAMv1.pdf) specification.\n",
    "\n",
    "| Col |\tField |\tType | Brief Description | Accessible through `HTSeq`? |\n",
    "|-----|-------|------|-------------------|-----------------------------|\n",
    "| 1 | QNAME | String | Query template NAME | No |\n",
    "| 2 | FLAG | Int bitwise | FLAG | Some |\n",
    "| 3 | RNAME | String | References sequence NAME | No |\n",
    "| 4 | POS | Int | 1- based leftmost mapping POSition | Yes |\n",
    "| 5 | MAPQ | Int | MAPping Quality | Yes |\n",
    "| 6 | CIGAR | String | CIGAR String | Yes | \n",
    "| 7 | RNEXT | String | Ref. name of the mate/next read | No (?) |\n",
    "| 8 | PNEXT | Int | Position of the mate/next read | Yes |\n",
    "| 9 | TLEN | Int | observed Template LENgth | No | \n",
    "| 10 | SEQ | String | segment SEQuence | Yes |\n",
    "| 11 | QUAL | String | ASCII of Phred-scaled base QUALity+33 | Yes | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `FLAG` field types\n",
    "\n",
    "| Bit | Description |\n",
    "|-----|-------------|\n",
    "| 0x1 | template having multiple segments in sequencing |\n",
    "| 0x2 | each segment properly aligned according to the aligner |\n",
    "| 0x4 | segment unmapped |\n",
    "| 0x8 | next segment in the template unmapped |\n",
    "| 0x10 | SEQ being reverse complemented |\n",
    "| 0x20 | SEQ of the next segment in the template being reverse complemented |\n",
    "| 0x40 | the first segment in the template | \n",
    "| 0x80 | the last segment in the template |\n",
    "| 0x100 | secondary alignment |\n",
    "| 0x200 | not passing filters, such as platform/vendor quality controls |\n",
    "| 0x400 | PCR or optical duplicate |\n",
    "| 0x800 | supplementary alignment |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1150004\n",
    "\n",
    "t_start3 = time.time()\n",
    "\n",
    "print(\"Printing the first {} reads in aln:\".format(sample_size))\n",
    "\n",
    "aln_alignment_reads = []\n",
    "\n",
    "for cnt, alignment_read in enumerate(itertools.islice(aln, sample_size)):\n",
    "    read_dict = {\n",
    "        \"Sequence\": str(alignment_read.read), \n",
    "        \"Aligned?\": alignment_read.aligned,\n",
    "        \"Coverage\": alignment_read.iv,\n",
    "        # \"Paired-end?\": alignment_read.paired-end, # This could probably be removed. NOT WORKING\n",
    "        \"Phred Score\": alignment_read.aQual,\n",
    "        \"CIGAR Objects\": alignment_read.cigar,\n",
    "        \"Secondary Alignment (0x100)\": alignment_read.not_primary_alignment,\n",
    "        \"Failed QC? (0x200)\": alignment_read.failed_platform_qc,\n",
    "        \"PCR/Optical duplicate? (0x400)\": alignment_read.pcr_or_optical_duplicate,\n",
    "        \"Chimeric Alignment (0x800)\": alignment_read.supplementary,\n",
    "        # \"Alignment Description\": alignment_read.get_sam_lines(), # NOT WORKING\n",
    "        \"Pairs Overlap?\": alignment_read.mate_aligned,\n",
    "        \"Both Pairs Aligned? (0x0002)\": alignment_read.proper_pair,\n",
    "        \"Which Pair Aligned?\": alignment_read.pe_which,\n",
    "        \"Alignment Start Position\": alignment_read.mate_start, # should be the same as `.iv.start`\n",
    "        \"Pair Gap Distance\": alignment_read.mate_start,\n",
    "        }\n",
    "    aln_alignment_reads.append(read_dict)  \n",
    "\n",
    "    print(cnt, \"Read Length: \", len(fastq_read), \"Average Phred Score: \", np.sum(fastq_read.qual)/len(fastq_read))\n",
    "\n",
    "# construct dataframe\n",
    "aln_df = pd.DataFrame(aln_alignment_reads)\n",
    "\n",
    "t_stop3 = time.time()\n",
    "t_total3 = t_stop3 - t_start3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head3 = 5\n",
    "print(\"There are \", len(aln_df.index), \" reads in this dataframe.\")\n",
    "print(\"This job took {} seconds to complete.\".format(t_total3))\n",
    "print(\"Printing the first {} rows of the dataframe:\".format(head3))\n",
    "aln_df.head(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the experiment meta-data invoking the `.optional_fields` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Some Thoughts__: Looking at how the `HTSeq.par_SAM_alignments` superclass is designed, I'm confused why the authors didn't just architect the superclass as described in the `SAM/BAM` format specifications.  I should be able to invoke a method to call whichever `flag` value is present in column 2 of the BAM Alignment section.  Instead, I'll have to either convert to the `SAM` format, or parse binary.  Also, `Pair Gap Distance` seems to be calling `Alignment Start Position`.  It's OK, It can be calculated from `Coverage`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff_file = hs.GFF_Reader(gff_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = hs.GenomicArray(\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `coverage`, which contains our read counts, is an `HTSeq._HTSeq.GenomicArray` class object, which is a dictionary for `HTSeq._HTSeq.GenomicInterval` class objects.  The `Coverage` column in `aln_df`, is also a `HTSeq._HTSeq.GenomicInterval` class object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1150004\n",
    "# 1150004\n",
    "\n",
    "aligned_total = 0\n",
    "\n",
    "t_start4 = time.time()\n",
    "\n",
    "for cnt, alignment_read in enumerate(itertools.islice(aln, sample_size)):\n",
    "    if alignment_read.aligned == True:\n",
    "        coverage[alignment_read.iv] += 1\n",
    "        aligned_total += 1\n",
    "\n",
    "not_aligned = sample_size - aligned_total\n",
    "\n",
    "t_stop4 = time.time()\n",
    "t_total4 = t_stop4 - t_start4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"It took {} seconds to scrape 1 column from aln_df.\".format(t_total4))\n",
    "print(\"Our BAM file contains {} sequencing reads that were classified as ALIGNED!\".format(aligned_total))\n",
    "print(\"Only {} reads failed to align correctly.\".format(not_aligned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what our coverage dictionary looks like\n",
    "\n",
    "for location, count in coverage.steps():\n",
    "    print(\"There are \", count, \" aligned reads at the following location: \", location, \".\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Transcription Start Sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the location of all transcription start sites, we can look in the `GFF` file for exons with `exon_number == 1` (as indicated by the `exon_number` attribute in Ensembl GFF files) and ask for their directional start (`start_d`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in itertools.islice(gff_file, 10):\n",
    "    print(feature.type)\n",
    "    for key, value in feature.attr.items():\n",
    "        print(\"\\n\", key, \"||||\", value)\n",
    "    # if feature.type == \"exon\" and feature.attr[\"exon_number\"] == \"1\":\n",
    "        \n",
    "        # print(feature.attr[\"gene_id\"], feature.attr[\"transcript_id\"], feature.iv.start_d_as_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAM/BAM Global Attributes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting BAM to SAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
